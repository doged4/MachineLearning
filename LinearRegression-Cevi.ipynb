{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "See basic example here:\n",
    "> http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares\n",
    "\n",
    "and full documentation of the linear_model module here:\n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display graphs in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy.random # for generating a noisy data set\n",
    "from sklearn import linear_model # for model fitting/training\n",
    "import matplotlib.pyplot # for plotting in general\n",
    "from mpl_toolkits.mplot3d import Axes3D # for 3D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_fit(model):\n",
    "    # Print out the parameters for the best fit line\n",
    "    print('Intercept: {0}  Coefficients: {1}'.format(model.intercept_, model.coef_))\n",
    "\n",
    "    # Print out the model's guesses for some values of x\n",
    "    datapoints = [[-1],[0],[1]]\n",
    "    predictions = model.predict(datapoints)\n",
    "    for datapoint, prediction in zip(datapoints, predictions):\n",
    "        print('Model prediction for {}: {}'.format(datapoint[0], prediction))\n",
    "\n",
    "def graph_one_input_model(model, x_1d, y):\n",
    "    # create the figure\n",
    "    fig = matplotlib.pyplot.figure(1)\n",
    "    fig.suptitle('Data and Best-Fit Line')\n",
    "    matplotlib.pyplot.xlabel('x')\n",
    "    matplotlib.pyplot.ylabel('y')\n",
    "\n",
    "    # put the generated dataset points on the graph\n",
    "    matplotlib.pyplot.scatter(x_1d, y)\n",
    "\n",
    "    # predict for inputs along the graph to find the best-fit line\n",
    "    X = numpy.linspace(MIN_X, MAX_X)\n",
    "    Y = model.predict(list(zip(X)))\n",
    "    matplotlib.pyplot.plot(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "\n",
    "This dataset still just has one input, so the code is very similar to our first one. However, now the generating function is quadratic, so this one will be trickier to deal with.\n",
    "\n",
    "Again, we'll go through dataset generation, training, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99d520a345cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate some normally distributed noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# randomly pick numbers for x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate some normally distributed noise\n",
    "noise = numpy.random.normal(size=100)\n",
    "\n",
    "# randomly pick numbers for x\n",
    "x2 = numpy.random.uniform(low=-10, high=10, size=(100, 1))\n",
    "\n",
    "# get a 1D array of the input data\n",
    "x2_1d = x2[:,0]\n",
    "\n",
    "# y = 0.7x^2 - 0.4x + 1.5\n",
    "y2 = 0.7 * x2_1d * x2_1d - 0.4 * x2_1d + 1.5 + noise\n",
    "\n",
    "# use scikit-learn's linear regression model and fit to our data\n",
    "model2 = linear_model.LinearRegression()\n",
    "model2.fit(x2, y2)\n",
    "\n",
    "# show results\n",
    "print_model_fit(model2)\n",
    "graph_one_input_model(model2, x2_1d, y2)\n",
    "\n",
    "#code:\n",
    "model6 = linear_model.LinearRegression()\n",
    "y6 = y2\n",
    "x6 = x2 * x2\n",
    "\n",
    "model6.fit(x6, y6)\n",
    "\n",
    "print_model_fit(model6)\n",
    "graph_one_input_model(model6, x6, y6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option (Advanced)\n",
    "\n",
    "Get the linear regression to work better for dataset 2. There are a couple different ways to do this, but all of them will involve some new code. If you have ideas but just aren't sure how to translate them into code, please ask for help!\n",
    "\n",
    "**Here blue represents the model before transformation, and the orange afterwards, where x<sup>2</sup> fits ~y<sup>2</sup> reasonably well, as the relationship is now linear. This techique is fantastic if you know what their relationship is likely to be, and makes analysis much more easy, but you have to know the broader function and degree.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "______________________________________________________________________________________________________________________\n",
    "______________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Dataset 3 (not worth reviewing)\n",
    "\n",
    "Finally, let's look at a dataset has two inputs, like [the tree example in our notes](https://jennselby.github.io/MachineLearningCourseNotes/#linear-regression).\n",
    "\n",
    "This will make it a littler harder to visualize, particularly because you cannot rotate the graph interactively in the Jupyter notebook. If you are interested in looking more closely at this graph, you can copy the code below (plus the code in the second and third code cells) into a file and run it through Python normally. This will open a graph window that will allow you to drag to rotate the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2effd5cf833e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# randomly pick pairs of numbers for x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the 2 in the size is how we get pairs instead of single numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_INPUTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get a 1D array of each input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "# randomly pick pairs of numbers for x\n",
    "# the 2 in the size is how we get pairs instead of single numbers\n",
    "x3 = numpy.random.uniform(low=MIN_X, high=MAX_X, size=(NUM_INPUTS, 2))\n",
    "\n",
    "# Get a 1D array of each input\n",
    "x3_1_1d = x3[:,0]\n",
    "x3_2_1d = x3[:,1]\n",
    "\n",
    "# y = 0.5x_1 - 0.2x_2 - 2\n",
    "y3 = 0.5 * x3_1_1d - 0.2 * x3_2_1d - 2 + noise\n",
    "\n",
    "# use scikit-learn's linear regression model and fit to our data\n",
    "model3 = linear_model.LinearRegression()\n",
    "model3.fit(x3, y3)\n",
    "\n",
    "# Print out the parameters for the best fit plane\n",
    "print('Intercept: {0}  Coefficients: {1}'.format(model3.intercept_, model3.coef_))\n",
    "\n",
    "# 3D Plot\n",
    "# create the figure\n",
    "fig = matplotlib.pyplot.figure(1)\n",
    "fig.suptitle('3D Data and Best-Fit Plane')\n",
    "\n",
    "# get the current axes, and tell them to do a 3D projection\n",
    "axes = fig.gca(projection='3d')\n",
    "axes.set_xlabel('x1')\n",
    "axes.set_ylabel('x2')\n",
    "axes.set_zlabel('y')\n",
    "\n",
    "# put the generated points on the graph\n",
    "axes.scatter(x3_1_1d, x3_2_1d, y3)\n",
    "\n",
    "# predict for input points across the graph to find the best-fit plane\n",
    "# and arrange them into a grid for matplotlib\n",
    "X1 = X2 = numpy.arange(MIN_X, MAX_X, 0.05)\n",
    "X1, X2 = numpy.meshgrid(X1, X2)\n",
    "Y = numpy.array(model3.predict(list(zip(X1.flatten(), X2.flatten())))).reshape(X1.shape)\n",
    "\n",
    "# put the predicted plane on the graph\n",
    "axes.plot_surface(X1, X2, Y, alpha=0.1)\n",
    "   \n",
    "# show the plots\n",
    "matplotlib.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option (Standard Difficulty)\n",
    "\n",
    "Answer the following questions about dataset 3:\n",
    "1. What output did you expect to see printed if the linear regression code was working, and why?\n",
    "1. What did you expect to see on the graph if the linear regression code was working, and why?\n",
    "1. Pick some lines of code that you could change to continue testing that the linear regression worked properly. What lines did you choose and how did you change them? How did the output change, and why does that tell you that the code is working correctly?\n",
    "1. Explain any differences you noticed between working with dataset 1 and dataset 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
