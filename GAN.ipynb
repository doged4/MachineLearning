{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8FqiNVtJbT1"
   },
   "source": [
    "Original code from https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py under the following license:\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2017 Erik Linder-NorÃ©n\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\n",
    "The author's model was based on the paper here: https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "# Installation\n",
    "\n",
    "1. Install h5, with `python3 -m pip install h5py`\n",
    "1. Download the three h5 files: [generator](https://github.com/jennselby/MachineLearningTutorials/raw/master/generator.h5), [discriminator](https://github.com/jennselby/MachineLearningTutorials/raw/master/discriminator.h5), and [combined](https://github.com/jennselby/MachineLearningTutorials/raw/master/combined.h5) and save them in the same folder as this file.\n",
    "\n",
    "### If you haven't already installed Keras, follow these directions\n",
    "\n",
    "1. Type `python3 --version` into Terminal. If the output starts with \"Python 3.6\", skip to step 3. **Tensorflow does not yet work with Python 3.7, so you _must_ get Python 3.6.** See https://github.com/tensorflow/tensorflow/issues/20517 for updates on 3.7 support.\n",
    "1. Go to https://www.python.org/downloads/ and click on \"Python 3.6.8\". Scroll down to the Files section and click on \"macOS 64-bit installer\". Run the installer and follow the directions. Repeat step 1 to make sure it has successfully installed. \n",
    "1. Set up Jupyter Notebook\n",
    "    * If you had already previously installed juypter notebook with Python 3.7:\n",
    "        1. Install ipykernel in Python 3.6. (_Make sure python3 is actually Python 3.6_!)\n",
    "            >`python3 -m pip install ipykernel`\n",
    "        1. Add this kernel as an option for your jupyter notebook:\n",
    "            >`python3 -m ipykernel install --user --name python-3-6 --display-name \"Python 3.6\"`\n",
    "    * Otherwise install jupyter notebook by typing the following into Terminal:\n",
    "        >`pip3 install jupyter`\n",
    "1. Start the jupyter notebook by typing in Terminal _in the same folder that you have this file_ \n",
    "    `jupyter notebook`\n",
    "    1. This should open a tab in your web browser with a list of files in the folder. Click on this ipynb file to open it.\n",
    "    1. If you installed a second kernel in step 3, go to the Kernel menu and choose \"Change Kernel\" and then select Python 3.6\n",
    "1. Install the tensorflow machine learning library by typing the following into Terminal:\n",
    "    >`python3 -m pip install --upgrade tensorflow`\n",
    "1. Install the keras machine learning library by typing the following into Terminal:\n",
    "    >`python3 -m pip install keras`\n",
    "1. Install the libraries we'll need to display the images:\n",
    "    > `python3 -m pip numpy matplotlib`\n",
    "1. Test that the keras install worked: Type `python3` into the Terminal. When the `>>>` prompt comes up, type `from keras.models import Sequential`. If you don't get any error output, then it worked. Type Ctrl+d (or close the window) to exit.\n",
    "    * If you get an error like `ModuleNotFoundError: No module named 'theano'` then you need to switch the backend to tensorflow. See the instructions at https://keras.io/backend/ or ask me for help.\n",
    "    * If you get a warning like `/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6` you can ignore it. This is a known (trivial) issue with Tensorflow 1.4 for OSX. See https://github.com/tensorflow/tensorflow/issues/14182 if you'd like more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNVQouEMJbT3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdaaGwLZJbT5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_-ayNQ3JbT7"
   },
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "images_dir = \"dcgan_images\"\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1\n",
    "noise_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nipbgSv_JbT9"
   },
   "source": [
    "## Define functions for creating, training, and using the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    '''\n",
    "    Put together a CNN that will return a single confidence output.\n",
    "    \n",
    "    returns: the model object\n",
    "    '''\n",
    "\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_generator():\n",
    "    '''\n",
    "    Put together a model that takes in one-dimensional noise and outputs two-dimensional\n",
    "    data representing a black and white image, with -1 for black and 1 for white.\n",
    "    \n",
    "    returns: the model object\n",
    "    '''\n",
    "\n",
    "    noise_shape = (noise_len,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_combined():\n",
    "    '''\n",
    "    Puts together a model that combines the discriminator and generator models.\n",
    "    \n",
    "    returns: the generator, discriminator, and combined model objects\n",
    "    '''\n",
    "    \n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Build and compile the generator\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # The generator takes noise as input and generates images\n",
    "    noise = Input(shape=(noise_len,))\n",
    "    img = generator(noise)\n",
    "    \n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # The combined model  (stacked generator and discriminator) takes\n",
    "    # noise as input => generates images => determines validity \n",
    "    combined = Model(inputs=noise, outputs=valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator, discriminator, combined\n",
    "\n",
    "def save_imgs(generator, epoch):\n",
    "    '''\n",
    "    Has the generator create images and saves the images in a single file that includes\n",
    "    the epoch in the filename.\n",
    "    \n",
    "    inputs:\n",
    "        generator: the generator model object returned by build_combined\n",
    "        epoch: the epoch number (but can be anything that can be represented as a string)\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, noise_len))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(images_dir, 'mnist_{}.png'.format(epoch)))\n",
    "    plt.close()\n",
    "\n",
    "def train(generator, discriminator, combined, epochs, batch_size=128, save_interval=50):\n",
    "    '''\n",
    "    Trains all model objects\n",
    "    \n",
    "    generator: the generator model object returned by build_combined\n",
    "    discriminator: the discriminator model object returned by build_combined\n",
    "    combined: the combined model object returned by build_combined\n",
    "    epochs: integer, the number of epochs to train for\n",
    "    batch_size: integer, the number of training samples to use at a time\n",
    "    save_interval: integer, will generate and save images when the current epoch % save_interval is 0\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, noise_len))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, noise_len))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # If at save interval => save generated image samples and plot progress\n",
    "        if epoch % save_interval == 0:\n",
    "            # Plot the progress\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print (\"{} [D loss: {}, acc.: {:.2%}] [G loss: {}]\".format(epoch, d_loss[0], d_loss[1], g_loss))\n",
    "            save_imgs(generator, epoch)\n",
    "            \n",
    "def show_new_image(generator):\n",
    "    '''\n",
    "    Generates and displays a new image\n",
    "    \n",
    "    inputs: generator object model returned from build_combined\n",
    "    \n",
    "    returns: generated image\n",
    "    '''\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (1, noise_len))\n",
    "    gen_img = generator.predict(noise)[0][:,:,0]\n",
    "    \n",
    "    return plt.imshow(gen_img, cmap='gray', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwreZ0dUJbT-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_discriminator():\n",
    "    '''\n",
    "    Put together a CNN that will return a single confidence output.\n",
    "    \n",
    "    returns: the model object\n",
    "    '''\n",
    "\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_generator():\n",
    "    '''\n",
    "    Put together a model that takes in one-dimensional noise and outputs two-dimensional\n",
    "    data representing a black and white image, with -1 for black and 1 for white.\n",
    "    \n",
    "    returns: the model object\n",
    "    '''\n",
    "\n",
    "    noise_shape = (noise_len,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_combined():\n",
    "    '''\n",
    "    Puts together a model that combines the discriminator and generator models.\n",
    "    \n",
    "    returns: the generator, discriminator, and combined model objects\n",
    "    '''\n",
    "    \n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Build and compile the generator\n",
    "    generator = build_generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # The generator takes noise as input and generates images\n",
    "    noise = Input(shape=(noise_len,))\n",
    "    img = generator(noise)\n",
    "    \n",
    "    # For the combined model we will only train the generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # The discriminator takes generated images as input and determines validity\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # The combined model  (stacked generator and discriminator) takes\n",
    "    # noise as input => generates images => determines validity \n",
    "    combined = Model(inputs=noise, outputs=valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator, discriminator, combined\n",
    "\n",
    "def save_imgs(generator, epoch):\n",
    "    '''\n",
    "    Has the generator create images and saves the images in a single file that includes\n",
    "    the epoch in the filename.\n",
    "    \n",
    "    inputs:\n",
    "        generator: the generator model object returned by build_combined\n",
    "        epoch: the epoch number (but can be anything that can be represented as a string)\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, noise_len))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(images_dir, 'mnist_{}.png'.format(epoch)))\n",
    "    plt.close()\n",
    "\n",
    "def train(generator, discriminator, combined, epochs, batch_size=128, save_interval=50):\n",
    "    '''\n",
    "    Trains all model objects\n",
    "    \n",
    "    generator: the generator model object returned by build_combined\n",
    "    discriminator: the discriminator model object returned by build_combined\n",
    "    combined: the combined model object returned by build_combined\n",
    "    epochs: integer, the number of epochs to train for\n",
    "    batch_size: integer, the number of training samples to use at a time\n",
    "    save_interval: integer, will generate and save images when the current epoch % save_interval is 0\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, noise_len))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, noise_len))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # If at save interval => save generated image samples and plot progress\n",
    "        if epoch % save_interval == 0:\n",
    "            # Plot the progress\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print (\"{} [D loss: {}, acc.: {:.2%}] [G loss: {}]\".format(epoch, d_loss[0], d_loss[1], g_loss))\n",
    "            save_imgs(generator, epoch)\n",
    "            \n",
    "def show_new_image(generator):\n",
    "    '''\n",
    "    Generates and displays a new image\n",
    "    \n",
    "    inputs: generator object model returned from build_combined\n",
    "    \n",
    "    returns: generated image\n",
    "    '''\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (1, noise_len))\n",
    "    gen_img = generator.predict(noise)[0][:,:,0]\n",
    "    \n",
    "    return plt.imshow(gen_img, cmap='gray', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvKSnD_iJbUD"
   },
   "source": [
    "## This is the main section of the code, that actually creates the model objects\n",
    "\n",
    "With the parameters below, the model training took almost 14 hours on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nsqTjZ-JbUD"
   },
   "outputs": [],
   "source": [
    "# set up directories to hold the images that are saved during training checkpoints.\n",
    "import os\n",
    "\n",
    "if (not os.path.isdir(images_dir)):\n",
    "    os.mkdir(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlAALQnpJbUH"
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want to build your own new models\n",
    "generator, discriminator, combined = build_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3jgEhvkJbUL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.8315361738204956, acc.: 46.88%] [G loss: 0.8007960915565491]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if you want to train your model (it took almost 14 hours on my laptop)\n",
    "train(generator, discriminator, combined, epochs=40, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK1Cl0dbJbUR"
   },
   "outputs": [],
   "source": [
    "# Uncomment to save your model files\n",
    "#generator.save('generator.h5')\n",
    "#discriminator.save('discriminator.h5')\n",
    "#combined.save('combined.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPqSYdjRJbUW"
   },
   "source": [
    "**Make sure that you have downloaded the three h5 files before running the next block.**\n",
    "\n",
    "Download the three h5 files: [generator](https://github.com/jennselby/MachineLearningTutorials/raw/master/generator.h5), [discriminator](https://github.com/jennselby/MachineLearningTutorials/raw/master/discriminator.h5), and [combined](https://github.com/jennselby/MachineLearningTutorials/raw/master/combined.h5) and save them in the same folder as this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "colab_type": "code",
    "id": "-JyN-tncJbUY",
    "outputId": "b9c56e6c-fad5-4262-8095-2601d05a6b5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model files. Comment out (or don't run) this block if you want to start\n",
    "# with fresh models.\n",
    "from keras.models import load_model\n",
    "\n",
    "generator = load_model('generator.h5')\n",
    "discriminator = load_model('discriminator.h5')\n",
    "combined = load_model('combined.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIcfkNX1JbUe"
   },
   "source": [
    "Let's see how it worked, by having the model generate some images for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "861GFV-ZJbUf",
    "outputId": "447ee8d2-27dc-4ed0-ab78-c6d2b4f7f485"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13bfb1a90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VK5yMyanJbUi",
    "outputId": "ea3f092a-cef2-4686-d366-da379aec0305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12cd6e358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzlzu8TaJbUl",
    "outputId": "1d9cc520-14c9-4a3e-e45c-838dca4c93e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12cdcbeb8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WF2k1FlWJbUw",
    "outputId": "cf8d7ecf-e3e7-4876-a075-c38b9b64eb44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12cf21710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_new_image(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9IrnbiqJbUz"
   },
   "source": [
    "# Exercise Option 1\n",
    "Change the model so that it learns to produce 9x9 images of some simple pattern, for instance horizontal lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzF_DlzFJbUz"
   },
   "source": [
    "# Exercise Option 2 (More Challenging)\n",
    "Change the model so that you can select which number you get an image of rather than always getting a random one. I highly recommend that you limit your model to only learning two or three numbers, so that you can get decent results with less training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HX2h_ekmJbU0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GAN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
